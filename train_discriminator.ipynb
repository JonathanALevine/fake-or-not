{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torcheval.metrics import BinaryAccuracy\n",
    "from torcheval.metrics.functional import binary_accuracy\n",
    "torch.manual_seed(18)\n",
    "torch.cuda.is_available()\n",
    "from DiscriminatorV3 import DiscriminatorV3, ConvBlock\n",
    "from DiscriminatorV4 import DiscriminatorV4, ConvBlock\n",
    "from FacesDataset import FacesDataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_system_out_string(epoch:int, train_loss:float, train_acc:float, val_loss:float, val_acc:float, test_acc:float)->str:\n",
    "    return (f'Epoch: {epoch} -- train Loss: {round(train_loss, 4)} \\t valid Loss: {round(val_loss, 4)} \\t train acc.:{round(train_acc, 4)} \\t val acc.:{round(val_acc, 4)} \\t test acc.:{round(test_acc, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_performance(model, data_loader, device='cuda'):\n",
    "    loss_value = 0.0\n",
    "    acc_value = 0.0\n",
    "    loss_fn = nn.BCELoss()\n",
    "    loss_fn.to(device)\n",
    "    metric = BinaryAccuracy()\n",
    "    metric.to(device)\n",
    "    model.eval()\n",
    "    for batch in tqdm(data_loader):\n",
    "        inputs, targets = batch\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs.flatten().float(), targets.float())\n",
    "        metric.update(outputs.flatten(), targets)\n",
    "        loss_value += loss.item()\n",
    "        acc_value += metric.compute().item()\n",
    "    return loss_value/data_loader.__len__(), acc_value/data_loader.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, test_loader, epochs, loss_fn, device='cuda'):\n",
    "    model.to(device)\n",
    "    loss_fn.to(device)\n",
    "    metric = BinaryAccuracy()\n",
    "    metric.to(device)\n",
    "\n",
    "    for epoch in (range(epochs)):\n",
    "        # train the model on the training set\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        model.train()\n",
    "        for batch in tqdm(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets = batch\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs.flatten().float(), targets.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            metric.update(outputs.flatten(), targets)\n",
    "            train_loss += loss.item()\n",
    "            train_acc += metric.compute().item()\n",
    "\n",
    "        # estimate the performance of the model on the validation set and the test set\n",
    "        train_loss, train_acc = train_loss / len(train_loader), train_acc / len(train_loader)\n",
    "        val_loss, val_acc = estimate_performance(model, val_loader, device)\n",
    "        test_loss, test_acc = estimate_performance(model, test_loader, device)\n",
    "\n",
    "        print(epoch_system_out_string(epoch, train_loss, train_acc, val_loss, val_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, test_loader, epochs, loss_fn, device='cuda'):\n",
    "    model.to(device)\n",
    "    loss_fn.to(device)\n",
    "    metric = BinaryAccuracy()\n",
    "    metric.to(device)\n",
    "\n",
    "    # Initialize empty dataframes\n",
    "    loss_df = pd.DataFrame(columns=['epoch', 'train_loss', 'val_loss'])\n",
    "    acc_df = pd.DataFrame(columns=['epoch', 'train_acc', 'val_acc'])\n",
    "\n",
    "    for epoch in (range(epochs)):\n",
    "        # train the model on the training set\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        model.train()\n",
    "        for batch in tqdm(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets = batch\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs.flatten().float(), targets.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            metric.update(outputs.flatten(), targets)\n",
    "            train_loss += loss.item()\n",
    "            train_acc += metric.compute().item()\n",
    "\n",
    "        # estimate the performance of the model on the validation set and the test set\n",
    "        train_loss, train_acc = train_loss / len(train_loader), train_acc / len(train_loader)\n",
    "        val_loss, val_acc = estimate_performance(model, val_loader, device)\n",
    "        test_loss, test_acc = estimate_performance(model, test_loader, device)\n",
    "        \n",
    "        # Add to dataframes\n",
    "        epoch_data = {'epoch': epoch+1,\n",
    "                    'train_loss': train_loss,\n",
    "                    'val_loss': val_loss,\n",
    "                    'test_loss': test_loss}\n",
    "        loss_df = pd.concat([loss_df, pd.DataFrame(epoch_data, index=[0])], ignore_index=True)\n",
    "        \n",
    "        epoch_data = {'epoch': epoch+1,\n",
    "                    'train_acc': train_acc,\n",
    "                    'val_acc': val_acc,\n",
    "                    'test_acc': test_acc}\n",
    "        acc_df = pd.concat([acc_df, pd.DataFrame(epoch_data, index=[0])], ignore_index=True)\n",
    "\n",
    "        print(epoch_system_out_string(epoch, train_loss, train_acc, val_loss, val_acc, test_acc))\n",
    "\n",
    "    # save dataframes to csv files\n",
    "    # Save data to CSV files\n",
    "    loss_df.to_csv('outputs/losses_V4.csv', index=False)\n",
    "    acc_df.to_csv('outputs/accuracies_V4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = FacesDataset('datasets/train.csv')\n",
    "train_loader = DataLoader(dataset=training_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_set = FacesDataset('datasets/valid.csv')\n",
    "valid_loader = DataLoader(dataset=valid_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_set = FacesDataset('datasets/test.csv')\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DiscriminatorV4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4534]], grad_fn=<SigmoidBackward0>), torch.Size([1, 1]))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(torch.randn(1, 3, 256, 256)), model.forward(torch.randn(1, 3, 256, 256)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "params = model.parameters()\n",
    "learning_rate = 3e-4\n",
    "optimizer = torch.optim.Adam(params, lr=learning_rate)\n",
    "\n",
    "# train the model\n",
    "num_epochs = 15\n",
    "train(model=model, optimizer=optimizer, train_loader=train_loader, val_loader=valid_loader, test_loader=test_loader,loss_fn=loss_fn, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
