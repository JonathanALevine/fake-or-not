{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torcheval.metrics import BinaryAccuracy\n",
    "from torcheval.metrics.functional import binary_accuracy\n",
    "torch.manual_seed(18)\n",
    "torch.cuda.is_available()\n",
    "from DiscriminatorV3 import DiscriminatorV3, ConvBlock\n",
    "from DiscriminatorV4 import DiscriminatorV4, ConvBlock\n",
    "from FacesDataset import FacesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_system_out_string(epoch:int, train_loss:float, train_acc:float, val_loss:float, val_acc:float, test_acc:float)->str:\n",
    "    return (f'Epoch: {epoch} -- train Loss: {round(train_loss, 4)} \\t valid Loss: {round(val_loss, 4)} \\t train acc.:{round(train_acc, 4)} \\t val acc.:{round(val_acc, 4)} \\t test acc.:{round(test_acc, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_performance(model, data_loader, device='cuda'):\n",
    "    loss_value = 0.0\n",
    "    acc_value = 0.0\n",
    "    loss_fn = nn.BCELoss()\n",
    "    loss_fn.to(device)\n",
    "    metric = BinaryAccuracy()\n",
    "    metric.to(device)\n",
    "    model.eval()\n",
    "    for batch in tqdm(data_loader):\n",
    "        inputs, targets = batch\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs.flatten().float(), targets.float())\n",
    "        metric.update(outputs.flatten(), targets)\n",
    "        loss_value += loss.item()\n",
    "        acc_value += metric.compute().item()\n",
    "    return loss_value/data_loader.__len__(), acc_value/data_loader.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, test_loader, epochs, loss_fn, device='cuda'):\n",
    "    model.to(device)\n",
    "    loss_fn.to(device)\n",
    "    metric = BinaryAccuracy()\n",
    "    metric.to(device)\n",
    "    for epoch in (range(epochs)):\n",
    "        # train the model on the training set\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        model.train()\n",
    "        for batch in tqdm(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets = batch\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs.flatten().float(), targets.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            metric.update(outputs.flatten(), targets)\n",
    "            train_loss += loss.item()\n",
    "            train_acc += metric.compute().item()\n",
    "\n",
    "        # estimate the performance of the model on the validation set and the test set\n",
    "        train_loss, train_acc = train_loss / len(train_loader), train_acc / len(train_loader)\n",
    "        val_loss, val_acc = estimate_performance(model, val_loader, device)\n",
    "        test_loss, test_acc = estimate_performance(model, test_loader, device)\n",
    "\n",
    "        print(epoch_system_out_string(epoch, train_loss, train_acc, val_loss, val_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = FacesDataset('datasets/train.csv')\n",
    "train_loader = DataLoader(dataset=training_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_set = FacesDataset('datasets/valid.csv')\n",
    "valid_loader = DataLoader(dataset=valid_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_set = FacesDataset('datasets/test.csv')\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DiscriminatorV3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4593]], grad_fn=<SigmoidBackward0>), torch.Size([1, 1]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(torch.randn(1, 3, 256, 256)), model.forward(torch.randn(1, 3, 256, 256)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [02:21<00:00, 88.61it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 100.44it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 103.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 -- train Loss: 0.6003 \t valid Loss: 0.5093 \t train acc.:0.5869 \t val acc.:0.7539 \t test acc.:0.7468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [02:20<00:00, 88.87it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 102.39it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 103.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 -- train Loss: 0.4278 \t valid Loss: 0.3709 \t train acc.:0.7009 \t val acc.:0.8378 \t test acc.:0.8426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [02:22<00:00, 88.01it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 100.91it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 101.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 -- train Loss: 0.3379 \t valid Loss: 0.3142 \t train acc.:0.7546 \t val acc.:0.8663 \t test acc.:0.8708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [02:20<00:00, 88.76it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 103.30it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 103.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 -- train Loss: 0.2853 \t valid Loss: 0.2996 \t train acc.:0.7877 \t val acc.:0.8735 \t test acc.:0.879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [02:22<00:00, 87.96it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 102.51it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 101.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 -- train Loss: 0.2524 \t valid Loss: 0.2542 \t train acc.:0.8103 \t val acc.:0.8974 \t test acc.:0.8934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [02:19<00:00, 89.38it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 101.61it/s]\n",
      "100%|██████████| 2500/2500 [00:25<00:00, 98.42it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 -- train Loss: 0.2273 \t valid Loss: 0.2562 \t train acc.:0.8268 \t val acc.:0.8944 \t test acc.:0.8986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [02:21<00:00, 88.26it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 101.37it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 102.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 -- train Loss: 0.2082 \t valid Loss: 0.2224 \t train acc.:0.8399 \t val acc.:0.9067 \t test acc.:0.9102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [02:22<00:00, 87.86it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 101.65it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 101.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 -- train Loss: 0.1922 \t valid Loss: 0.2113 \t train acc.:0.8505 \t val acc.:0.9132 \t test acc.:0.9175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [02:20<00:00, 88.68it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 102.95it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 102.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 -- train Loss: 0.1813 \t valid Loss: 0.1969 \t train acc.:0.8593 \t val acc.:0.9177 \t test acc.:0.9236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2903/12500 [00:33<01:53, 84.76it/s]"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "params = model.parameters()\n",
    "learning_rate = 3e-4\n",
    "optimizer = torch.optim.Adam(params, lr=learning_rate)\n",
    "\n",
    "# train the model\n",
    "num_epochs = 15\n",
    "train(model=model, optimizer=optimizer, train_loader=train_loader, val_loader=valid_loader, test_loader=test_loader,loss_fn=loss_fn, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
