{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torcheval.metrics import BinaryAccuracy\n",
    "from torcheval.metrics.functional import binary_accuracy\n",
    "torch.manual_seed(18)\n",
    "torch.cuda.is_available()\n",
    "from FacesDataset import FacesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DiscriminatorV3 import DiscriminatorV3, ConvBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Generator import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, discriminator, optimizer, epochs, loss_fn, device='cuda'):\n",
    "    target = torch.tensor([0.0]).to(device)\n",
    "    \n",
    "    generator.to(device)\n",
    "    discriminator.to(device)\n",
    "\n",
    "    generator.eval()\n",
    "    discriminator.train()\n",
    "\n",
    "    loss_fn.to(device)\n",
    "    metric = BinaryAccuracy()\n",
    "    metric.to(device)\n",
    "    for epoch in (range(epochs)):\n",
    "        # train the model on the training set\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.randn(1, 32).to(device)\n",
    "        generated_image_tensor = generator.forward(x)\n",
    "        output = discriminator.forward(generated_image_tensor)\n",
    "        loss = loss_fn(output.flatten().float(), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        metric.update(output.flatten(), target)\n",
    "    print(round(output.item(), 4), round(loss.item(), 4), metric.compute().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = DiscriminatorV3()\n",
    "discriminator.load_state_dict(torch.load('models/FaceNetV3-Batch-8.pth'))\n",
    "\n",
    "generator = Generator()\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "params = discriminator.parameters()\n",
    "learning_rate = 3e-4\n",
    "optimizer = torch.optim.Adam(params, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the discriminator on the generator's output\n",
    "num_epochs = 100\n",
    "train(generator=generator, discriminator=discriminator, optimizer=optimizer, loss_fn=loss_fn, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.5863e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "device = 'cuda'\n",
    "x = torch.randn(1, 32).to(device)\n",
    "generated_image_tensor = generator.forward(x)\n",
    "print(discriminator.forward(generated_image_tensor))\n",
    "transforms.ToPILImage()(generated_image_tensor.squeeze(0)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, discriminator, optimizer, epochs, loss_fn, device='cuda'):\n",
    "    target = torch.tensor([0.0]).to(device)\n",
    "    \n",
    "    generator.to(device)\n",
    "    discriminator.to(device)\n",
    "\n",
    "    generator.eval()\n",
    "    discriminator.train()\n",
    "\n",
    "    loss_fn.to(device)\n",
    "    metric = BinaryAccuracy()\n",
    "    metric.to(device)\n",
    "    for epoch in (range(epochs)):\n",
    "        # train the model on the training set\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.randn(1, 32).to(device)\n",
    "        generated_image_tensor = generator.forward(x)\n",
    "        output = discriminator.forward(generated_image_tensor)\n",
    "        loss = loss_fn(output.flatten().float(), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        metric.update(output.flatten(), target)\n",
    "    print(round(output.item(), 4), round(loss.item(), 4), metric.compute().item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
